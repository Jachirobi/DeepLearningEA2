<!DOCTYPE html>
<html lang="de">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Regression mit FFNN und TensorFlow.js</title>
<link rel="stylesheet" href="style.css">
<script
	src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.13.0/dist/tf.min.js"></script>
<script
	src="https://cdnjs.cloudflare.com/ajax/libs/seedrandom/3.0.5/seedrandom.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
</head>
<body>
	<div id="loadingOverlay">
		<div class="spinner"></div>
		<p id="loadingText">🔄 Modelle werden vorbereitet...</p>
	</div>
	<div class="container">
		<header>
			<div class="header-inhalt">
				<h1>Regression mit Neuronalen Netzen</h1>
				<button id="darkModeToggle" aria-pressed="false"
					aria-label="Dark Mode umschalten"
					title="Hell-/Dunkelmodus umschalten">🌙 Dark Mode
					aktivieren</button>
			</div>
		</header>

		<div class="allgemeine-informationen collapsible-section">
			<div class="section-header">
				<h2>Aufgabenstellung</h2>
				<button class="toggle-button" aria-expanded="true"
					aria-controls="aufgaben-section"
					title="Abschnitt ein- oder ausklappen">⬇️ Einklappen</button>
			</div>
			<div class="section-content" id="aufgaben-section">
				<p>
					Nutzen Sie ein <strong>Feed-Forward Neural Network (FFNN)</strong>
					als Modell zur Regression der reellwertigen Funktion:
				</p>
				<p>y(x) = 0.5*(x+0.8)*(x+1.8)*(x-0.2)*(x-0.3)*(x-1.9) + 1 auf
					dem Intervall [-2, +2] (Definitionsmenge).</p>
				<p>Wir wollen simulieren, wie es im richtigen Leben ist, das
					bedeutet, Sie kennen die Funktion y(x) nicht (das ist die
					unbekannte Ground-Truth). Stattdessen generieren Sie Daten von
					dieser Funktion und verrauschen diese.</p>

				<h3>A1) Datengenerierung</h3>
				<p>
					Erzeugen Sie N = 100 zufällige, gleichverteilte x-Werte im
					Intervall [-2, +2].<br> Berechnen Sie y(x) für diese x-Werte.
					Sie erhalten einen unverrauschten Datensatz aus 100 (x, y) Paaren.<br>
					Teilen Sie den Datensatz zufällig in 50 Trainings- und 50 Testdaten
					auf.<br> Fügen Sie anschließend normalverteiltes Rauschen
					(Gaussian Noise) mit Varianz V = 0.05 zu den y-Werten (Labels)
					hinzu.<br> (x-Werte bleiben unverrauscht.)<br> Sie haben
					nun zwei Datensätze: einen ohne und einen mit Rauschen, jeweils
					aufgeteilt in Trainings- und Testdaten.
				</p>

				<h3>A2) Modelltraining (unverrauschte Daten)</h3>
				<p>
					Trainieren Sie ein Modell auf den unverrauschten Trainingsdaten.<br>
					Da kein Rauschen vorhanden ist, sollte das Modell auf den Testdaten
					etwa denselben Fehler (Loss) aufweisen wie auf den Trainingsdaten
					(Loss_train ≈ Loss_test).<br> Ohne Rauschen tritt kein
					Overfitting auf.
				</p>

				<h3>A3) Modelltraining (verrauschte Daten – Best-Fit)</h3>
				<p>
					Trainieren Sie ein erstes Modell auf dem verrauschten Datensatz mit
					einer moderaten Anzahl an Epochen.<br> Ziel ist eine möglichst
					gute Generalisierung und ein geringer Loss (MSE) auf den Testdaten.
				</p>

				<h3>A4) Modelltraining (verrauschte Daten – Over-Fit)</h3>
				<p>
					Trainieren Sie ein zweites Modell auf demselben verrauschten
					Datensatz, jedoch so lange, bis es overfittet.<br> Overfitting
					zeigt sich daran, dass der Trainings-Loss deutlich geringer wird
					als der Test-Loss (Loss_train << Loss_test).
				</p>
			</div>
		</div>

		<div class="daten-config collapsible-section">
			<div class="section-header">
				<h3>Datenparameter konfigurieren</h3>
				<button class="toggle-button" aria-expanded="true"
					aria-controls="aufgaben-section"
					title="Abschnitt ein- oder ausklappen">⬇️ Einklappen</button>
			</div>
			<div class="section-content" id="aufgaben-section">
				<label for="numPoints">Anzahl Datenpunkte (N) von 50 bis 500
					einstellbar:</label> <input type="range" id="numPoints" min="50" max="500"
					step="10" value="100" title="Anzahl der Datenpunkte (N)"> <span
					id="numPointsValue">100</span> <label for="noiseVar">Rauschvarianz
					(V) von 0,01 bis 0,50 einstellbar:</label> <input type="range"
					id="noiseVar" min="0.01" max="0.5" step="0.01" value="0.05"
					title="Rauschvarianz (V)"> <span id="noiseVarValue">0.05</span>

				<button id="applyDataParams" class="config-button"
					title="Neue Daten generieren">🔁 Daten neu generieren</button>
			</div>
		</div>

		<div class="model-config collapsible-section">
			<div class="section-header">
				<h3>Modellarchitektur konfigurieren</h3>
				<button class="toggle-button" aria-expanded="true"
					aria-controls="aufgaben-section"
					title="Abschnitt ein- oder ausklappen">⬇️ Einklappen</button>
			</div>
			<div class="section-content" id="aufgaben-section">
				<label for="numHiddenLayers">Anzahl der Hidden-Layer (1-3):</label>
				<select id="numHiddenLayers" title="Anzahl der Hidden-Layer wählen">
					<option value="1">1</option>
					<option value="2" selected>2</option>
					<option value="3">3</option>
				</select> <label for="neuronsLayer1">Neuronen in Layer 1 (1-500):</label> <input
					type="number" id="neuronsLayer1" min="1" max="500" value="100"
					title="Anzahl der Neuronen im ersten Hidden-Layer. Mehr Neuronen erhöhen die Modellkomplexität.">

				<label for="neuronsLayer2">Neuronen in Layer 2 (1-500):</label> <input
					type="number" id="neuronsLayer2" min="1" max="500" value="100"
					title="Anzahl der Neuronen im ersten Hidden-Layer. Mehr Neuronen erhöhen die Modellkomplexität.">

				<label for="neuronsLayer3">Neuronen in Layer 3 (1-500):</label> <input
					type="number" id="neuronsLayer3" min="1" max="500" value="100"
					title="Anzahl der Neuronen im ersten Hidden-Layer. Mehr Neuronen erhöhen die Modellkomplexität.">
				<!-- Aktivierung wählen -->
				<label for="activationSelect">Aktivierungsfunktion:</label> <select
					id="activationSelect" title="Aktivierungsfunktion wählen">
					<option value="relu">ReLU (Standard)</option>
					<option value="tanh">tanh</option>
				</select>
				<button id="applyArchitecture" class="config-button"
					title="Architektur ändern und Modelle neu trainieren">🔁
					Architektur ändern</button>
			</div>
		</div>

		<aside class="linkeSeite">
			<h2>R1) Unverrauschte Daten</h2>
			<div id="plot-daten-unverrauscht" class="grid-container"></div>
		</aside>
		<aside class="rechteSeite">
			<h2>R1) Verrauschte Daten</h2>
			<div id="plot-daten-verrauscht" class="grid-container"></div>
		</aside>

		<aside class="linkeSeiteE">
			<h2>R2) Modell auf Unverrauscht (Train)</h2>
			<div id="plot-vorhersage-train-clean" class="grid-container"></div>
		</aside>
		<aside class="rechteSeiteE">
			<h2>R2) Modell auf Unverrauscht (Test)</h2>
			<div id="plot-vorhersage-test-clean" class="grid-container"></div>
		</aside>
		<aside class="linkeSeiteE2">
			<h2>R3) Best-Fit Modell (Train)</h2>
			<div id="plot-vorhersage-train-best" class="grid-container"></div>
		</aside>
		<aside class="rechteSeiteE2">
			<h2>R3) Best-Fit Modell (Test)</h2>
			<div id="plot-vorhersage-test-best" class="grid-container"></div>
		</aside>
		<div class="epochen-regler"
			style="grid-column: 1/span 2; text-align: center;">
			<label for="epochSlider"><strong>Epochen für
					Best-Fit Modell (50-300):</strong></label> <input type="range" id="epochSlider"
				min="50" max="300" value="117" step="10"
				title="Epochenanzahl für Best-Fit Modell einstellen"> <span
				id="epochValue">117 Epochen ausgewählt</span>
		</div>
		<aside class="linkerechteSeiteE2">
			<h2>R3) Lernkurve: Loss vs. Epoch</h2>
			<div id="loss-chart-container" class="grid-container"></div>
		</aside>

		<aside class="linkeSeiteE3">
			<h2>R4) Overfit Modell (Train)</h2>
			<div id="plot-vorhersage-train" class="grid-container"></div>
		</aside>
		<aside class="rechteSeiteE3">
			<h2>R4) Overfit Modell (Test)</h2>
			<div id="plot-vorhersage-test" class="grid-container"></div>
		</aside>
		<div class="epochen-regler2"
			style="grid-column: 1/span 2; text-align: center;">
			<label for="epochSlider2"><strong>Epochen für
					Overfit Modell (300-20000):</strong></label> <input type="range" id="epochSlider2"
				min="300" max="20000" value="2000" step="100"
				title="Epochenanzahl für Overfit Modell einstellen"> <span
				id="epochValue2">2000 Epochen ausgewählt</span>
		</div>
		<aside class="linkerechteSeiteE3">
			<h2>R4) Lernkurve: Loss vs. Epoch</h2>
			<div id="loss-chart-container2" class="grid-container"></div>
			<!-- Fortschrittsanzeige für Overfit -->
			<div id="progress-overfit"
				style="margin-top: 10px; font-weight: bold; color: #e67e22;">
				Lernkurve wird geladen</div>
			<button id="toggle-screenshot" class="config-button"
				style="margin-top: 10px;"
				title="Screenshot-Vorschau für 20000 Epochen ein-/ausblenden">📷
				Vorschau für 20000 Epochen anzeigen (bezogen auf Einstellungen der
				Aufgabenstellung)</button>
			<div id="screenshot-container"
				style="display: none; margin-top: 10px;">
				<img id="screenshot-img" src="overfit-details.png"
					alt="Overfit Screenshot Details"
					style="max-width: 100%; border-radius: 8px; box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);">
			</div>
		</aside>

		<section class="experimente collapsible-section">
			<div class="section-header">
				<h2>Experimente und Fragestellungen</h2>
				<button class="toggle-button" aria-expanded="true"
					aria-controls="experimente-section"
					title="Abschnitt ein- oder ausklappen">⬇️ Einklappen</button>
			</div>
			<div class="section-content" id="experimente-section">
				<p>Zusätzlich zur Grundaufgabe wurden im Rahmen der Experimente
					verschiedene Aspekte des Lernverhaltens und der
					Generalisierungsfähigkeit des Feedforward Neural Networks (FFNN)
					systematisch untersucht:</p>

				<h3>1) Einfluss der Modellarchitektur</h3>
				<p>Erhöht man die Anzahl der Hidden-Layer von 1 oder 2 auf 3
					und/oder die Anzahl der Neuronen pro Layer, lernt das Modell
					schneller und kann die Trainingsdaten sehr gut bestimmen (Best-Fit
					tritt früher ein). Dabei zeigte sich, dass Overfitting in diesem
					Setup (glatte Ziel-Funktion, relativ viele Datenpunkte) nicht
					unmittelbar auftrat, sondern erst bei sehr hohen Epochenzahlen.
					Dies liegt unter anderem daran, dass ein großes Netzwerk bei einer
					glatten Funktion zunächst eine längere "Underfitting"-Phase
					durchläuft und erst mit fortschreitendem Training beginnt, das
					vorhandene Rauschen in den Daten zu modellieren. Gerade bei stärker
					verrauschten Daten war dennoch beobachtbar, dass Overfitting früher
					und stärker auftrat, je größer die Architektur war.</p>

				<p>Die Wahl der Aktivierungsfunktion zeigte, dass ReLU gegenüber
					tanh eine stabilere Konvergenz und geringeres Overfitting-Verhalten
					aufwies.</p>

				<h3>2) Einfluss der Datenmenge</h3>
				<p>Bei einer Reduktion der Datenpunkte auf N = 50 (25 Train, 25
					Test) war eine starke Überanpassung sichtbar; das Modell lernte die
					Trainingsdaten, konnte aber nicht mehr gut generalisieren,
					Overfitting trat früher auf. Bei Erhöhung auf N = 200 oder N = 500
					wurde das Modell deutlich robuster und generalisierte wesentlich
					besser. Overfitting trat später oder gar nicht mehr auf.</p>

				<h3>3) Einfluss der Rauschstärke</h3>
				<p>Bei starker Rauschvarianz (V ≥ 0.3) war es kaum noch möglich,
					ein Modell zu trainieren, das die zugrunde liegende Funktion
					zuverlässig abbildet. Bereits bei V = 0.1 zeigten sich leichte
					Einbußen in der Generalisierung. Bei sehr niedrigem Rauschen (V ≤
					0.01) entsprach das Verhalten weitgehend dem unverrauschten Fall.</p>

				<h3>4) Einfluss der Lernrate</h3>
				<p>Eine Lernrate von 0.01 erwies sich als gut geeignet. Bei
					0.001 war das Training sehr langsam. Höhere Lernraten (≥ 0.05)
					führten oft zu instabilem Verhalten oder Divergenz. Zu kleine
					Lernraten brachten zudem die Gefahr von "zu frühem Overfitting", da
					das Modell zu langsam optimierte.</p>

				<h3>5) Dynamik des Overfittings</h3>
				<p>Die Beobachtung der Lernkurven (Train-Loss vs. Test-Loss)
					zeigte: Overfitting begann meist zwischen 500 und 15000 Epochen, je
					nach Rauschen und Architektur. Bei höherer Modellkomplexität und
					geringer Datenmenge trat Overfitting früher auf. Ein typisches
					Signal war das Auseinanderdriften der Loss-Kurven nach einer Phase
					synchronen Abfalls.</p>

				<h3>6) Stabilität bei unterschiedlicher Initialisierung</h3>
				<p>Mehrere Läufe mit unterschiedlichen Startwerten zeigten, dass
					bei konstanter Architektur und Datenmenge die Resultate recht
					stabil blieben. Bei kleinen Datensätzen (N = 50) und hohem Rauschen
					waren die Schwankungen deutlich größer (z. B. Test-MSE von 0.1 bis
					0.3).</p>

				<h3>7) Generalisierung außerhalb des Trainingsbereichs</h3>
				<p>Ein Experiment mit x-Werten im Bereich [-3, +3] zeigte, dass
					das Modell erwartungsgemäß nur im Trainingsbereich [-2, +2]
					zuverlässig vorhersagen konnte. Außerhalb dieses Bereichs
					extrapolierte es stark unsicher und produzierte unrealistische
					Werte. Dies unterstreicht die Bedeutung einer geeigneten
					Datenabdeckung im Trainingsbereich.</p>

				<h3>Fazit</h3>
				<p>Die durchgeführten Experimente haben eindrucksvoll gezeigt,
					wie Modellarchitektur, Datenmenge, Rauschstärke und
					Optimierungsparameter das Lern- und Generalisierungsverhalten eines
					neuronalen Netzes beeinflussen. Besonders wichtig ist dabei das
					sorgfältige Monitoring von Overfitting anhand der Test-Loss-Kurve.
					Die Nutzung von TensorFlow.js und die dynamische Visualisierung im
					Browser erwiesen sich als sehr hilfreiche Werkzeuge für diese
					Analyse.</p>
			</div>
		</section>


		<div class="diskussion collapsible-section">
			<div class="section-header">
				<h2>Diskussion</h2>
				<button class="toggle-button" aria-expanded="true"
					aria-controls="aufgaben-section"
					title="Abschnitt ein- oder ausklappen">⬇️ Einklappen</button>
			</div>
			<div class="section-content" id="aufgaben-section">
				<p>Für die Regression der gegebenen Funktion wurde ein
					Feedforward Neural Network (FFNN) mit konfigurierbarer Architektur
					eingesetzt (2 Hidden-Layer, je 100 Neuronen, ReLU-Aktivierung,
					Adam-Optimizer mit Lernrate 0.01 und Batch-Size 32). Die Anzahl der
					Datenpunkte (N) und die Rauschvarianz (V) wurden gemäß Vorgabe
					flexibel gestaltet (hier typischerweise N = 100, V = 0.05). Dadurch
					konnten gezielt Auswirkungen von Datenmenge und Rauschstärke auf
					das Modellverhalten untersucht werden.</p>
				<p>
					Auf den <strong>unverrauschten Daten</strong> zeigte das Modell bei
					einer Epochenzahl von 1000 ein sehr gutes Fit-Verhalten (Train- und
					Test-MSE < 0.0001). Bei den <strong>verrauschten Daten</strong>
					führte ein Bereich von ca. 100-300 Epochen zu einer ausgewogenen
					Generalisierung (Train-MSE ~0.04-0.06, Test-MSE ~0.06-0.08). Bei
					sehr hoher Epochenanzahl (ab ca. 15.000) konnte Overfitting
					deutlich beobachtet werden: der Train-Loss sinkt weiter (&lt;0.02),
					während der Test-Loss ansteigt (&gt;0.12 bei 15.000 und &gt;0.32
					bei 20.000).
				</p>
				<p>Änderungen an der Architektur (z.B. zusätzliche Layer oder
					mehr Neuronen) zeigten, dass komplexere Modelle tendenziell
					schneller zu Overfitting neigen, insbesondere bei kleinen
					Datensätzen oder hoher Rauschvarianz. Ebenso wirkt sich die Wahl
					der Aktivierungsfunktion auf die Lernstabilität aus (ReLU erwies
					sich hier als robust). Die Erhöhung der Datenpunkte führte hingegen
					zu einem schnelleren Best-Fit Verhalten und einer Angleichung
					zwischen Test- und Trainings-MSE sowie einem viel späteren
					Overt-Fit.</p>
				<p>Insgesamt hat dieses Experiment sehr anschaulich
					verdeutlicht, wie Modellkomplexität, Trainingsdauer, Datenmenge und
					Rauschlevel gemeinsam das Lern- und Generalisierungsverhalten eines
					neuronalen Netzes bestimmen.</p>
			</div>
		</div>

		<main class="collapsible-section">
			<div class="section-header">
				<h2>Dokumentation</h2>
				<button class="toggle-button" aria-expanded="true"
					aria-controls="aufgaben-section"
					title="Abschnitt ein- oder ausklappen">⬇️ Einklappen</button>
			</div>
			<div class="section-content" id="aufgaben-section">
				<h3>1) Technisch</h3>
				<p>In der Lösung wurden folgende Frameworks und Libraries
					verwendet:</p>
				<ul>
					<li><strong>TensorFlow.js</strong>: zur Implementierung und
						Ausführung des neuronalen Netzes (FFNN) direkt im Browser
						(Training, Evaluation und Inferenz).</li>
					<li><strong>Chart.js</strong>: zur Visualisierung der
						Lernkurven (Train- und Test-Loss über Epochen).</li>
					<li><strong>Plotly.js</strong>: zur Visualisierung der Daten
						und Modellvorhersagen (Streuplott der tatsächlichen und
						vorhergesagten Werte).</li>
				</ul>
				<p>
					Technische Besonderheiten der Lösung: Das gesamte Training und die
					Modellberechnungen erfolgen vollständig clientseitig im Browser mit
					TensorFlow.js, ohne Server oder Backend. Die Lernkurve wird
					performant aufgebaut, indem der Train-Loss direkt aus
					<code>fit()</code>
					und der Test-Loss gezielt mit
					<code>evaluate()</code>
					ermittelt wird. Zusätzlich sind interaktive Steuerelemente (Slider
					und Dropdowns) integriert, um Datenparameter (N, Rauschvarianz) und
					Modellarchitektur (Layer, Neuronen, Aktivierungsfunktion) dynamisch
					anzupassen. Eine Fortschrittsanzeige informiert während des
					Trainings über den aktuellen Stand.
				</p>

				<h3>2) Fachlich</h3>
				<p>Die Logik der Implementierung orientiert sich an der
					Aufgabenstellung: Zunächst wird ein unverrauschter Datensatz
					generiert und für das Modelltraining genutzt. Anschließend werden
					verrauschte Daten erzeugt und in zwei Varianten trainiert (Best-Fit
					und Overfit), um die Auswirkungen von Epochenzahl und
					Modellkomplexität auf die Generalisierungsfähigkeit zu untersuchen.
					Für das Training wird der Adam-Optimizer mit Lernrate 0.01 und
					Batch-Size 32 eingesetzt. Die Modelle bestehen aus 1–3
					Hidden-Layern mit konfigurierbarer Neuronenzahl und
					ReLU-Aktivierung; der Output-Layer ist linear.</p>
				<p>Durch die einheitliche und kontrollierte Visualisierung der
					Lernkurven sowie der Modellvorhersagen konnten wichtige Effekte wie
					Overfitting und Bias-Variance-Verhalten beobachtet und
					nachvollzogen werden. Besonderer Wert wurde darauf gelegt, die
					Testdaten strikt nur zur Evaluation zu verwenden, um eine
					realistische Einschätzung der Modellgeneraliserung zu
					gewährleisten.</p>
				<p>Um den Nutzer Hilfestellungen zu geben, wurden an den
					wichtigsten Stellen Tooltips integriert. Für die Barrierefreiheit
					wurde versucht alles zu berücksichtigen. Dazu gehören
					beispielsweise aria-label, alt-texte oder Kontraste bei der
					Farbauswahl.</p>
				<p>
					Quellen: TensorFlow.js Dokumentation (<a
						href="https://js.tensorflow.org" target="_blank">https://js.tensorflow.org</a>),
					Chart.js Dokumentation (<a href="https://www.chartjs.org"
						target="_blank">https://www.chartjs.org</a>), Plotly.js (<a
						href="https://plotly.com/javascript/" target="_blank">https://plotly.com/javascript/</a>),
					begleitende Vorlesungsfolien und Übungsmaterialien.
				</p>
			</div>
		</main>
		<footer>Thomas Brehmer</footer>
	</div>

	<script src="script.js"></script>
</body>
</html>
