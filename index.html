<!DOCTYPE html>
<html lang="de">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Regression mit FFNN und TensorFlow.js</title>
<link rel="stylesheet" href="style.css">
<script
	src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.13.0/dist/tf.min.js"></script>
<script
	src="https://cdnjs.cloudflare.com/ajax/libs/seedrandom/3.0.5/seedrandom.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
</head>
<body>
	<div id="loadingOverlay">
		<div class="spinner"></div>
		<p id="loadingText">üîÑ Modelle werden vorbereitet...</p>
	</div>
	<div class="container">
		<header>
			<div class="header-inhalt">
				<h1>Regression mit Neuronalen Netzen</h1>
				<button id="darkModeToggle" aria-pressed="false"
					aria-label="Dark Mode umschalten"
					title="Hell-/Dunkelmodus umschalten">üåô Dark Mode
					aktivieren</button>
			</div>
		</header>

		<div class="allgemeine-informationen collapsible-section">
			<div class="section-header">
				<h2>Aufgabenstellung</h2>
				<button class="toggle-button" aria-expanded="true"
					aria-controls="aufgaben-section"
					title="Abschnitt ein- oder ausklappen">‚¨áÔ∏è Einklappen</button>
			</div>
			<div class="section-content" id="aufgaben-section">
				<p>
					Nutzen Sie ein <strong>Feed-Forward Neural Network (FFNN)</strong>
					als Modell zur Regression der reellwertigen Funktion:
				</p>
				<p>y(x) = 0.5*(x+0.8)*(x+1.8)*(x-0.2)*(x-0.3)*(x-1.9) + 1 auf
					dem Intervall [-2, +2] (Definitionsmenge).</p>
				<p>Wir wollen simulieren, wie es im richtigen Leben ist, das
					bedeutet, Sie kennen die Funktion y(x) nicht (das ist die
					unbekannte Ground-Truth). Stattdessen generieren Sie Daten von
					dieser Funktion und verrauschen diese.</p>

				<h3>A1) Datengenerierung</h3>
				<p>
					Erzeugen Sie N = 100 zuf√§llige, gleichverteilte x-Werte im
					Intervall [-2, +2].<br> Berechnen Sie y(x) f√ºr diese x-Werte.
					Sie erhalten einen unverrauschten Datensatz aus 100 (x, y) Paaren.<br>
					Teilen Sie den Datensatz zuf√§llig in 50 Trainings- und 50 Testdaten
					auf.<br> F√ºgen Sie anschlie√üend normalverteiltes Rauschen
					(Gaussian Noise) mit Varianz V = 0.05 zu den y-Werten (Labels)
					hinzu.<br> (x-Werte bleiben unverrauscht.)<br> Sie haben
					nun zwei Datens√§tze: einen ohne und einen mit Rauschen, jeweils
					aufgeteilt in Trainings- und Testdaten.
				</p>

				<h3>A2) Modelltraining (unverrauschte Daten)</h3>
				<p>
					Trainieren Sie ein Modell auf den unverrauschten Trainingsdaten.<br>
					Da kein Rauschen vorhanden ist, sollte das Modell auf den Testdaten
					etwa denselben Fehler (Loss) aufweisen wie auf den Trainingsdaten
					(Loss_train ‚âà Loss_test).<br> Ohne Rauschen tritt kein
					Overfitting auf.
				</p>

				<h3>A3) Modelltraining (verrauschte Daten ‚Äì Best-Fit)</h3>
				<p>
					Trainieren Sie ein erstes Modell auf dem verrauschten Datensatz mit
					einer moderaten Anzahl an Epochen.<br> Ziel ist eine m√∂glichst
					gute Generalisierung und ein geringer Loss (MSE) auf den Testdaten.
				</p>

				<h3>A4) Modelltraining (verrauschte Daten ‚Äì Over-Fit)</h3>
				<p>
					Trainieren Sie ein zweites Modell auf demselben verrauschten
					Datensatz, jedoch so lange, bis es overfittet.<br> Overfitting
					zeigt sich daran, dass der Trainings-Loss deutlich geringer wird
					als der Test-Loss (Loss_train << Loss_test).
				</p>
			</div>
		</div>

		<div class="daten-config collapsible-section">
			<div class="section-header">
				<h3>Datenparameter konfigurieren</h3>
				<button class="toggle-button" aria-expanded="true"
					aria-controls="aufgaben-section"
					title="Abschnitt ein- oder ausklappen">‚¨áÔ∏è Einklappen</button>
			</div>
			<div class="section-content" id="aufgaben-section">
				<label for="numPoints">Anzahl Datenpunkte (N) von 50 bis 500
					einstellbar:</label> <input type="range" id="numPoints" min="50" max="500"
					step="10" value="100" title="Anzahl der Datenpunkte (N)"> <span
					id="numPointsValue">100</span> <label for="noiseVar">Rauschvarianz
					(V) von 0,01 bis 0,50 einstellbar:</label> <input type="range"
					id="noiseVar" min="0.01" max="0.5" step="0.01" value="0.05"
					title="Rauschvarianz (V)"> <span id="noiseVarValue">0.05</span>

				<button id="applyDataParams" class="config-button"
					title="Neue Daten generieren">üîÅ Daten neu generieren</button>
			</div>
		</div>

		<div class="model-config collapsible-section">
			<div class="section-header">
				<h3>Modellarchitektur konfigurieren</h3>
				<button class="toggle-button" aria-expanded="true"
					aria-controls="aufgaben-section"
					title="Abschnitt ein- oder ausklappen">‚¨áÔ∏è Einklappen</button>
			</div>
			<div class="section-content" id="aufgaben-section">
				<label for="numHiddenLayers">Anzahl der Hidden-Layer (1-3):</label>
				<select id="numHiddenLayers" title="Anzahl der Hidden-Layer w√§hlen">
					<option value="1">1</option>
					<option value="2" selected>2</option>
					<option value="3">3</option>
				</select> <label for="neuronsLayer1">Neuronen in Layer 1 (1-500):</label> <input
					type="number" id="neuronsLayer1" min="1" max="500" value="100"
					title="Anzahl der Neuronen im ersten Hidden-Layer. Mehr Neuronen erh√∂hen die Modellkomplexit√§t.">

				<label for="neuronsLayer2">Neuronen in Layer 2 (1-500):</label> <input
					type="number" id="neuronsLayer2" min="1" max="500" value="100"
					title="Anzahl der Neuronen im ersten Hidden-Layer. Mehr Neuronen erh√∂hen die Modellkomplexit√§t.">

				<label for="neuronsLayer3">Neuronen in Layer 3 (1-500):</label> <input
					type="number" id="neuronsLayer3" min="1" max="500" value="100"
					title="Anzahl der Neuronen im ersten Hidden-Layer. Mehr Neuronen erh√∂hen die Modellkomplexit√§t.">
				<!-- Aktivierung w√§hlen -->
				<label for="activationSelect">Aktivierungsfunktion:</label> <select
					id="activationSelect" title="Aktivierungsfunktion w√§hlen">
					<option value="relu">ReLU (Standard)</option>
					<option value="tanh">tanh</option>
				</select>
				<button id="applyArchitecture" class="config-button"
					title="Architektur √§ndern und Modelle neu trainieren">üîÅ
					Architektur √§ndern</button>
			</div>
		</div>

		<aside class="linkeSeite">
			<h2>R1) Unverrauschte Daten</h2>
			<div id="plot-daten-unverrauscht" class="grid-container"></div>
		</aside>
		<aside class="rechteSeite">
			<h2>R1) Verrauschte Daten</h2>
			<div id="plot-daten-verrauscht" class="grid-container"></div>
		</aside>

		<aside class="linkeSeiteE">
			<h2>R2) Modell auf Unverrauscht (Train)</h2>
			<div id="plot-vorhersage-train-clean" class="grid-container"></div>
		</aside>
		<aside class="rechteSeiteE">
			<h2>R2) Modell auf Unverrauscht (Test)</h2>
			<div id="plot-vorhersage-test-clean" class="grid-container"></div>
		</aside>
		<aside class="linkeSeiteE2">
			<h2>R3) Best-Fit Modell (Train)</h2>
			<div id="plot-vorhersage-train-best" class="grid-container"></div>
		</aside>
		<aside class="rechteSeiteE2">
			<h2>R3) Best-Fit Modell (Test)</h2>
			<div id="plot-vorhersage-test-best" class="grid-container"></div>
		</aside>
		<div class="epochen-regler"
			style="grid-column: 1/span 2; text-align: center;">
			<label for="epochSlider"><strong>Epochen f√ºr
					Best-Fit Modell (50-300):</strong></label> <input type="range" id="epochSlider"
				min="50" max="300" value="117" step="10"
				title="Epochenanzahl f√ºr Best-Fit Modell einstellen"> <span
				id="epochValue">117 Epochen ausgew√§hlt</span>
		</div>
		<aside class="linkerechteSeiteE2">
			<h2>R3) Lernkurve: Loss vs. Epoch</h2>
			<div id="loss-chart-container" class="grid-container"></div>
		</aside>

		<aside class="linkeSeiteE3">
			<h2>R4) Overfit Modell (Train)</h2>
			<div id="plot-vorhersage-train" class="grid-container"></div>
		</aside>
		<aside class="rechteSeiteE3">
			<h2>R4) Overfit Modell (Test)</h2>
			<div id="plot-vorhersage-test" class="grid-container"></div>
		</aside>
		<div class="epochen-regler2"
			style="grid-column: 1/span 2; text-align: center;">
			<label for="epochSlider2"><strong>Epochen f√ºr
					Overfit Modell (300-20000):</strong></label> <input type="range" id="epochSlider2"
				min="300" max="20000" value="2000" step="100"
				title="Epochenanzahl f√ºr Overfit Modell einstellen"> <span
				id="epochValue2">2000 Epochen ausgew√§hlt</span>
		</div>
		<aside class="linkerechteSeiteE3">
			<h2>R4) Lernkurve: Loss vs. Epoch</h2>
			<div id="loss-chart-container2" class="grid-container"></div>
			<!-- Fortschrittsanzeige f√ºr Overfit -->
			<div id="progress-overfit"
				style="margin-top: 10px; font-weight: bold; color: #e67e22;">
				Lernkurve wird geladen</div>
			<button id="toggle-screenshot" class="config-button"
				style="margin-top: 10px;"
				title="Screenshot-Vorschau f√ºr 20000 Epochen ein-/ausblenden">üì∑
				Vorschau f√ºr 20000 Epochen anzeigen (bezogen auf Einstellungen der
				Aufgabenstellung)</button>
			<div id="screenshot-container"
				style="display: none; margin-top: 10px;">
				<img id="screenshot-img" src="overfit-details.png"
					alt="Overfit Screenshot Details"
					style="max-width: 100%; border-radius: 8px; box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);">
			</div>
		</aside>

		<section class="experimente collapsible-section">
			<div class="section-header">
				<h2>Experimente und Fragestellungen</h2>
				<button class="toggle-button" aria-expanded="true"
					aria-controls="experimente-section"
					title="Abschnitt ein- oder ausklappen">‚¨áÔ∏è Einklappen</button>
			</div>
			<div class="section-content" id="experimente-section">
				<p>Zus√§tzlich zur Grundaufgabe wurden im Rahmen der Experimente
					verschiedene Aspekte des Lernverhaltens und der
					Generalisierungsf√§higkeit des Feedforward Neural Networks (FFNN)
					systematisch untersucht:</p>

				<h3>1) Einfluss der Modellarchitektur</h3>
				<p>Erh√∂ht man die Anzahl der Hidden-Layer von 1 oder 2 auf 3
					und/oder die Anzahl der Neuronen pro Layer, lernt das Modell
					schneller und kann die Trainingsdaten sehr gut bestimmen (Best-Fit
					tritt fr√ºher ein). Dabei zeigte sich, dass Overfitting in diesem
					Setup (glatte Ziel-Funktion, relativ viele Datenpunkte) nicht
					unmittelbar auftrat, sondern erst bei sehr hohen Epochenzahlen.
					Dies liegt unter anderem daran, dass ein gro√ües Netzwerk bei einer
					glatten Funktion zun√§chst eine l√§ngere "Underfitting"-Phase
					durchl√§uft und erst mit fortschreitendem Training beginnt, das
					vorhandene Rauschen in den Daten zu modellieren. Gerade bei st√§rker
					verrauschten Daten war dennoch beobachtbar, dass Overfitting fr√ºher
					und st√§rker auftrat, je gr√∂√üer die Architektur war.</p>

				<p>Die Wahl der Aktivierungsfunktion zeigte, dass ReLU gegen√ºber
					tanh eine stabilere Konvergenz und geringeres Overfitting-Verhalten
					aufwies.</p>

				<h3>2) Einfluss der Datenmenge</h3>
				<p>Bei einer Reduktion der Datenpunkte auf N = 50 (25 Train, 25
					Test) war eine starke √úberanpassung sichtbar; das Modell lernte die
					Trainingsdaten, konnte aber nicht mehr gut generalisieren,
					Overfitting trat fr√ºher auf. Bei Erh√∂hung auf N = 200 oder N = 500
					wurde das Modell deutlich robuster und generalisierte wesentlich
					besser. Overfitting trat sp√§ter oder gar nicht mehr auf.</p>

				<h3>3) Einfluss der Rauschst√§rke</h3>
				<p>Bei starker Rauschvarianz (V ‚â• 0.3) war es kaum noch m√∂glich,
					ein Modell zu trainieren, das die zugrunde liegende Funktion
					zuverl√§ssig abbildet. Bereits bei V = 0.1 zeigten sich leichte
					Einbu√üen in der Generalisierung. Bei sehr niedrigem Rauschen (V ‚â§
					0.01) entsprach das Verhalten weitgehend dem unverrauschten Fall.</p>

				<h3>4) Einfluss der Lernrate</h3>
				<p>Eine Lernrate von 0.01 erwies sich als gut geeignet. Bei
					0.001 war das Training sehr langsam. H√∂here Lernraten (‚â• 0.05)
					f√ºhrten oft zu instabilem Verhalten oder Divergenz. Zu kleine
					Lernraten brachten zudem die Gefahr von "zu fr√ºhem Overfitting", da
					das Modell zu langsam optimierte.</p>

				<h3>5) Dynamik des Overfittings</h3>
				<p>Die Beobachtung der Lernkurven (Train-Loss vs. Test-Loss)
					zeigte: Overfitting begann meist zwischen 500 und 15000 Epochen, je
					nach Rauschen und Architektur. Bei h√∂herer Modellkomplexit√§t und
					geringer Datenmenge trat Overfitting fr√ºher auf. Ein typisches
					Signal war das Auseinanderdriften der Loss-Kurven nach einer Phase
					synchronen Abfalls.</p>

				<h3>6) Stabilit√§t bei unterschiedlicher Initialisierung</h3>
				<p>Mehrere L√§ufe mit unterschiedlichen Startwerten zeigten, dass
					bei konstanter Architektur und Datenmenge die Resultate recht
					stabil blieben. Bei kleinen Datens√§tzen (N = 50) und hohem Rauschen
					waren die Schwankungen deutlich gr√∂√üer (z. B. Test-MSE von 0.1 bis
					0.3).</p>

				<h3>7) Generalisierung au√üerhalb des Trainingsbereichs</h3>
				<p>Ein Experiment mit x-Werten im Bereich [-3, +3] zeigte, dass
					das Modell erwartungsgem√§√ü nur im Trainingsbereich [-2, +2]
					zuverl√§ssig vorhersagen konnte. Au√üerhalb dieses Bereichs
					extrapolierte es stark unsicher und produzierte unrealistische
					Werte. Dies unterstreicht die Bedeutung einer geeigneten
					Datenabdeckung im Trainingsbereich.</p>

				<h3>Fazit</h3>
				<p>Die durchgef√ºhrten Experimente haben eindrucksvoll gezeigt,
					wie Modellarchitektur, Datenmenge, Rauschst√§rke und
					Optimierungsparameter das Lern- und Generalisierungsverhalten eines
					neuronalen Netzes beeinflussen. Besonders wichtig ist dabei das
					sorgf√§ltige Monitoring von Overfitting anhand der Test-Loss-Kurve.
					Die Nutzung von TensorFlow.js und die dynamische Visualisierung im
					Browser erwiesen sich als sehr hilfreiche Werkzeuge f√ºr diese
					Analyse.</p>
			</div>
		</section>


		<div class="diskussion collapsible-section">
			<div class="section-header">
				<h2>Diskussion</h2>
				<button class="toggle-button" aria-expanded="true"
					aria-controls="aufgaben-section"
					title="Abschnitt ein- oder ausklappen">‚¨áÔ∏è Einklappen</button>
			</div>
			<div class="section-content" id="aufgaben-section">
				<p>F√ºr die Regression der gegebenen Funktion wurde ein
					Feedforward Neural Network (FFNN) mit konfigurierbarer Architektur
					eingesetzt (2 Hidden-Layer, je 100 Neuronen, ReLU-Aktivierung,
					Adam-Optimizer mit Lernrate 0.01 und Batch-Size 32). Die Anzahl der
					Datenpunkte (N) und die Rauschvarianz (V) wurden gem√§√ü Vorgabe
					flexibel gestaltet (hier typischerweise N = 100, V = 0.05). Dadurch
					konnten gezielt Auswirkungen von Datenmenge und Rauschst√§rke auf
					das Modellverhalten untersucht werden.</p>
				<p>
					Auf den <strong>unverrauschten Daten</strong> zeigte das Modell bei
					einer Epochenzahl von 1000 ein sehr gutes Fit-Verhalten (Train- und
					Test-MSE < 0.0001). Bei den <strong>verrauschten Daten</strong>
					f√ºhrte ein Bereich von ca. 100-300 Epochen zu einer ausgewogenen
					Generalisierung (Train-MSE ~0.04-0.06, Test-MSE ~0.06-0.08). Bei
					sehr hoher Epochenanzahl (ab ca. 15.000) konnte Overfitting
					deutlich beobachtet werden: der Train-Loss sinkt weiter (&lt;0.02),
					w√§hrend der Test-Loss ansteigt (&gt;0.12 bei 15.000 und &gt;0.32
					bei 20.000).
				</p>
				<p>√Ñnderungen an der Architektur (z.B. zus√§tzliche Layer oder
					mehr Neuronen) zeigten, dass komplexere Modelle tendenziell
					schneller zu Overfitting neigen, insbesondere bei kleinen
					Datens√§tzen oder hoher Rauschvarianz. Ebenso wirkt sich die Wahl
					der Aktivierungsfunktion auf die Lernstabilit√§t aus (ReLU erwies
					sich hier als robust). Die Erh√∂hung der Datenpunkte f√ºhrte hingegen
					zu einem schnelleren Best-Fit Verhalten und einer Angleichung
					zwischen Test- und Trainings-MSE sowie einem viel sp√§teren
					Overt-Fit.</p>
				<p>Insgesamt hat dieses Experiment sehr anschaulich
					verdeutlicht, wie Modellkomplexit√§t, Trainingsdauer, Datenmenge und
					Rauschlevel gemeinsam das Lern- und Generalisierungsverhalten eines
					neuronalen Netzes bestimmen.</p>
			</div>
		</div>

		<main class="collapsible-section">
			<div class="section-header">
				<h2>Dokumentation</h2>
				<button class="toggle-button" aria-expanded="true"
					aria-controls="aufgaben-section"
					title="Abschnitt ein- oder ausklappen">‚¨áÔ∏è Einklappen</button>
			</div>
			<div class="section-content" id="aufgaben-section">
				<h3>1) Technisch</h3>
				<p>In der L√∂sung wurden folgende Frameworks und Libraries
					verwendet:</p>
				<ul>
					<li><strong>TensorFlow.js</strong>: zur Implementierung und
						Ausf√ºhrung des neuronalen Netzes (FFNN) direkt im Browser
						(Training, Evaluation und Inferenz).</li>
					<li><strong>Chart.js</strong>: zur Visualisierung der
						Lernkurven (Train- und Test-Loss √ºber Epochen).</li>
					<li><strong>Plotly.js</strong>: zur Visualisierung der Daten
						und Modellvorhersagen (Streuplott der tats√§chlichen und
						vorhergesagten Werte).</li>
				</ul>
				<p>
					Technische Besonderheiten der L√∂sung: Das gesamte Training und die
					Modellberechnungen erfolgen vollst√§ndig clientseitig im Browser mit
					TensorFlow.js, ohne Server oder Backend. Die Lernkurve wird
					performant aufgebaut, indem der Train-Loss direkt aus
					<code>fit()</code>
					und der Test-Loss gezielt mit
					<code>evaluate()</code>
					ermittelt wird. Zus√§tzlich sind interaktive Steuerelemente (Slider
					und Dropdowns) integriert, um Datenparameter (N, Rauschvarianz) und
					Modellarchitektur (Layer, Neuronen, Aktivierungsfunktion) dynamisch
					anzupassen. Eine Fortschrittsanzeige informiert w√§hrend des
					Trainings √ºber den aktuellen Stand.
				</p>

				<h3>2) Fachlich</h3>
				<p>Die Logik der Implementierung orientiert sich an der
					Aufgabenstellung: Zun√§chst wird ein unverrauschter Datensatz
					generiert und f√ºr das Modelltraining genutzt. Anschlie√üend werden
					verrauschte Daten erzeugt und in zwei Varianten trainiert (Best-Fit
					und Overfit), um die Auswirkungen von Epochenzahl und
					Modellkomplexit√§t auf die Generalisierungsf√§higkeit zu untersuchen.
					F√ºr das Training wird der Adam-Optimizer mit Lernrate 0.01 und
					Batch-Size 32 eingesetzt. Die Modelle bestehen aus 1‚Äì3
					Hidden-Layern mit konfigurierbarer Neuronenzahl und
					ReLU-Aktivierung; der Output-Layer ist linear.</p>
				<p>Durch die einheitliche und kontrollierte Visualisierung der
					Lernkurven sowie der Modellvorhersagen konnten wichtige Effekte wie
					Overfitting und Bias-Variance-Verhalten beobachtet und
					nachvollzogen werden. Besonderer Wert wurde darauf gelegt, die
					Testdaten strikt nur zur Evaluation zu verwenden, um eine
					realistische Einsch√§tzung der Modellgeneraliserung zu
					gew√§hrleisten.</p>
				<p>Um den Nutzer Hilfestellungen zu geben, wurden an den
					wichtigsten Stellen Tooltips integriert. F√ºr die Barrierefreiheit
					wurde versucht alles zu ber√ºcksichtigen. Dazu geh√∂ren
					beispielsweise aria-label, alt-texte oder Kontraste bei der
					Farbauswahl.</p>
				<p>
					Quellen: TensorFlow.js Dokumentation (<a
						href="https://js.tensorflow.org" target="_blank">https://js.tensorflow.org</a>),
					Chart.js Dokumentation (<a href="https://www.chartjs.org"
						target="_blank">https://www.chartjs.org</a>), Plotly.js (<a
						href="https://plotly.com/javascript/" target="_blank">https://plotly.com/javascript/</a>),
					begleitende Vorlesungsfolien und √úbungsmaterialien.
				</p>
			</div>
		</main>
		<footer>Thomas Brehmer</footer>
	</div>

	<script src="script.js"></script>
</body>
</html>
